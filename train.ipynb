{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config\n",
    "RANDOM_SEED = 14\n",
    "SEED = 14\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 10\n",
    "WEIGHT_DECAY = 1e-2\n",
    "num_epoch = 200\n",
    "device = 'cuda:0'\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.sequence = [s[0] for s in data]\n",
    "        self.targets = [s[1] for s in data]\n",
    "        self.mask = [(s[2]) for s in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequence[idx], self.targets[idx], self.mask[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.encoder = torch.nn.TransformerEncoder(\n",
    "            encoder_layer=torch.nn.TransformerEncoderLayer(d_model=8, nhead=4, dim_feedforward=128, dropout=0.1, activation='relu'),\n",
    "            num_layers=6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(data):\n",
    "    tmp_data = []\n",
    "    tmp_target = []\n",
    "    tmp_mask = []\n",
    "    for i in range(len(data)):\n",
    "        for itr2 in range(len(data[i][0])):\n",
    "            for itr3 in range(len(data[i][0][itr2])):\n",
    "                data[i][0][itr2][itr3] /= 16\n",
    "                data[i][1][itr2][itr3] /= 16\n",
    "        tmp_data.append(data[i][0])\n",
    "        tmp_target.append(data[i][1])\n",
    "        tmp_mask.append(data[i][2])\n",
    "    return [torch.Tensor(tmp_data), torch.Tensor(tmp_target), tmp_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./dataset.pickle', 'rb')\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "f = open('./dataset_mask.pickle', 'rb')\n",
    "data_mask = pickle.load(f)\n",
    "f.close()\n",
    "f = open('./dataset_target.pickle', 'rb')\n",
    "data_target = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for itr1 in data_target.keys():\n",
    "    data_list.append((data[str(itr1)], data_target[str(itr1)], data_mask[str(itr1)]))\n",
    "\n",
    "dataset = MyDataset(data_list)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True, num_workers = NUM_WORKERS, collate_fn = collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# print(len(dataloader))\n",
    "for data in iter(dataloader):\n",
    "    # print(inputs)\n",
    "    # print(labels)\n",
    "    # print(mask)\n",
    "    print(len(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.nn.Linear(16,8)\n",
    "encoder = encoder.to(device)\n",
    "decoder = torch.nn.Linear(8,16)\n",
    "decoder = decoder.to(device)\n",
    "softmax_fn = torch.nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0625,  ..., -0.0625, -0.0625, -0.0625]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0625,  ..., -0.0625, -0.0625, -0.0625]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0625,  ..., -0.0625, -0.0625, -0.0625],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.9375,  0.8750,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0625,  ..., -0.0625, -0.0625, -0.0625],\n",
      "         [ 0.9375,  1.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.9375,  0.0000,  1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0625,  ..., -0.0625, -0.0625, -0.0625],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0625,  ..., -0.0625, -0.0625, -0.0625],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000]]]), tensor([[[0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.9375, 0.8750, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.9375, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.9375, 0.0000, 1.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9375,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]]]), [[23, 18, 17], [10, 23, 12], [1, 3, 22], [19, 8, 7], [23, 17, 19], [16, 4, 15], [18, 4, 23], [16, 1, 3], [2, 8, 23], [11, 20, 21], [11, 19, 9], [3, 10, 19], [19, 2, 7], [11, 9, 21], [21, 2, 19], [20, 10, 16], [10, 8, 16], [19, 12, 7], [0, 7, 6], [8, 22, 14], [16, 23, 3], [8, 18, 6], [12, 19, 22], [19, 18, 17], [18, 2, 5], [22, 20, 13], [19, 2, 13], [17, 5, 8], [8, 18, 1], [18, 16, 17], [22, 16, 19], [13, 17, 2]]]\n"
     ]
    }
   ],
   "source": [
    "for test in dataloader:\n",
    "    print(test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4994, 0.1406, 0.1566, 0.0599, 0.1436],\n",
      "        [0.0839, 0.3648, 0.2633, 0.1661, 0.1219],\n",
      "        [0.3424, 0.1231, 0.2603, 0.1792, 0.0950]])\n",
      "tensor([[-0.8328,  1.8499,  0.5260,  0.5182,  0.3945],\n",
      "        [ 0.6742,  0.5450,  1.3759, -0.1513, -0.3500],\n",
      "        [-0.0338, -1.3396, -0.4590,  2.7691,  0.7530]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2772, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(target)\n",
    "print(input)\n",
    "loss_fn(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./exp_cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch :0:   0%|          | 0/15564 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_196553/3749185225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# target2 = softmax_fn(data[1][itr1][data[2][itr1][1]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# target3 = softmax_fn(data[1][itr1][data[2][itr1][2]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target1' is not defined"
     ]
    }
   ],
   "source": [
    "# val_acc_history = []\n",
    "# loss_history = []\n",
    "# best_model_wts = copy.deepcopy(model.state_dict())\n",
    "# best_finetune_model = copy.deepcopy(finetune.state_dict())\n",
    "train_steps = 1\n",
    "# This loss is for\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion_2 = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=WEIGHT_DECAY)\n",
    "for epoch in range(num_epoch):\n",
    "    # tqdm.set_description('\\nEpoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    loss = 0.0\n",
    "        # Iterate over data.\n",
    "    data_set = tqdm(iter(dataloader), desc = f'Epoch :{epoch}')\n",
    "    for data in data_set:\n",
    "        ## the label has been normalize in the collate_fn\n",
    "        # for itr1 in range(len(data[0])):\n",
    "        #     data[0][itr1] = torch.nn.functional.normalize(data[0][itr1])\n",
    "        inputs = data[0].to('cuda:0')\n",
    "        # finetune = finetune.to('cuda:0')\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # Get model outputs and calculate loss\n",
    "        inputs = encoder(inputs)\n",
    "        outputs = model(inputs)\n",
    "        outputs = decoder(outputs)\n",
    "        outputs = outputs.to('cpu')\n",
    "        # print(len(outputs))\n",
    "        for itr1 in range(len(outputs)):\n",
    "            # target1 = softmax_fn(data[1][itr1][data[2][itr1][0]])\n",
    "            # target2 = softmax_fn(data[1][itr1][data[2][itr1][1]])\n",
    "            # target3 = softmax_fn(data[1][itr1][data[2][itr1][2]])\n",
    "            ## the target has been normalize in the collate_fn\n",
    "            target1 = data[1][itr1][data[2][itr1][0]]\n",
    "            target2 = data[1][itr1][data[2][itr1][1]]\n",
    "            target3 = data[1][itr1][data[2][itr1][2]]\n",
    "            loss = criterion(torch.unsqueeze(outputs[itr1][data[2][itr1][0]], dim = 0), torch.unsqueeze(target1, dim = 0))\n",
    "            loss += criterion(torch.unsqueeze(outputs[itr1][data[2][itr1][1]], dim = 0), torch.unsqueeze(target2, dim = 0))\n",
    "            loss += criterion(torch.unsqueeze(outputs[itr1][data[2][itr1][2]], dim = 0), torch.unsqueeze(target3, dim = 0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_steps += 1\n",
    "\n",
    "        if(train_steps % 100) == 0:\n",
    "            data_set.set_description(f'Epoch :{epoch}' + f' loss :{round(loss.item(), 3)}')\n",
    "            writer.add_scalar('training_loss', loss.item(), train_steps)\n",
    "        if(train_steps % 10000) == 0:\n",
    "            torch.save(model.state_dict(), './exp_cross/pretrain_' + str(train_steps) + '.model')\n",
    "            torch.save(encoder.state_dict(), './exp_cross/encoder_' + str(train_steps) + '.model')\n",
    "            torch.save(decoder.state_dict(), './exp_cross/decoder_' + str(train_steps) + '.model')\n",
    "            torch.save(optimizer.state_dict(), './exp_cross/optimizer_' + str(train_steps) + '.model')\n",
    "# load best model weights\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# finetune.load_state_dict(best_finetune_model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d2fb2da1ead284111eca66b5f71903e4ac9fc311b7a7d2c42b50e9190f68909"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
