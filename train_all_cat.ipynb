{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config\n",
    "RANDOM_SEED = 14\n",
    "SEED = 14\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-3\n",
    "EPOCHS = 10\n",
    "WEIGHT_DECAY = 1e-2\n",
    "num_epoch = 200\n",
    "device = 'cuda:0'\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.sequence = [s[0] for s in data]\n",
    "        self.targets = [s[1] for s in data]\n",
    "        self.ids = [s[2] for s in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequence[idx], self.targets[idx], self.ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.hidden_size = 7\n",
    "        self.input_size = 6\n",
    "        # self.embedding_size = 5\n",
    "        # self.id_encoder = torch.nn.Embedding(16, self.embedding_size)\n",
    "        self.conv1 = torch.nn.Conv1d(16, 16, 7, padding=0)\n",
    "        # self.maxpooling = torch.nn.MaxPool1d(kernel_size=5, padding=2, stride=1)\n",
    "        self.conv2 = torch.nn.Conv1d(16, 16, 7, padding=0)\n",
    "        self.conv3 = torch.nn.Conv1d(16, 16, 7, padding=0)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = self.input_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = 4,\n",
    "            batch_first = True,\n",
    "            dropout = 0.1,\n",
    "            bidirectional = False,\n",
    "        )\n",
    "        self.encoder_origin_1 = torch.nn.Linear(23, 64)\n",
    "        self.encoder_cnn_1 = torch.nn.Linear(17 * 3, 128)\n",
    "        self.encoder_lstm_1 = torch.nn.Linear(self.hidden_size, 32)\n",
    "\n",
    "        self.encoder_origin_2 = torch.nn.Linear(64, 256)\n",
    "        self.encoder_cnn_2 =  torch.nn.Linear(128, 512)\n",
    "        self.encoder_lstm_2 = torch.nn.Linear(32, 128)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p = 0.1)\n",
    "\n",
    "        self.feedforward_origin_1 = torch.nn.Linear(256, 256)\n",
    "        self.feedforward_cnn_1 = torch.nn.Linear(512, 512)\n",
    "        self.feedforward_lstm_1 = torch.nn.Linear(128, 128)\n",
    "\n",
    "        self.decoder_origin_1 = torch.nn.Linear(256, 64)\n",
    "        self.decoder_cnn_1 = torch.nn.Linear(512, 128)\n",
    "        self.decoder_lstm_1 = torch.nn.Linear(128, 32)\n",
    "\n",
    "        self.decoder_origin_2 = torch.nn.Linear(64, 16)\n",
    "        self.decoder_cnn_2 = torch.nn.Linear(128, 32)\n",
    "        self.decoder_lstm_2 = torch.nn.Linear(32, 8)\n",
    "\n",
    "        self.decoder_origin_3 = torch.nn.Linear(16, 4)\n",
    "        self.decoder_cnn_3 = torch.nn.Linear(32, 8)\n",
    "        self.decoder_lstm_3 = torch.nn.Linear(8, 2)\n",
    "\n",
    "        self.predict = torch.nn.Linear(14, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size()[0]\n",
    "\n",
    "        a = self.conv1(x)\n",
    "        b = self.conv2(x)\n",
    "        c = self.conv3(x)\n",
    "        d = x.unsqueeze(dim = 3)\n",
    "\n",
    "        tmp_list = []\n",
    "        d_list = d.tolist()\n",
    "\n",
    "        for itr1 in range(len(d_list)):\n",
    "            for itr2 in range(len(d_list[itr1])):\n",
    "                for itr3 in range(0, 23 - self.input_size + 1):\n",
    "                    for itr4 in range(self.input_size - 1):\n",
    "                        d_list[itr1][itr2][itr3].append(d_list[itr1][itr2][itr3 + itr4][0])\n",
    "                d_list[itr1][itr2] = d_list[itr1][itr2][:itr3 + 1]\n",
    "\n",
    "        d = torch.Tensor(d_list)\n",
    "        d = d.to(device)\n",
    "\n",
    "        for i in range(batch):\n",
    "            tmp_list.append(torch.unsqueeze(torch.squeeze(self.lstm(d[i])[0][ :, -1:, :], dim=1), dim = 0))\n",
    "\n",
    "        lstm_output = torch.cat(tmp_list, dim = 0)\n",
    "        cnn = torch.cat((a, b, c), dim = 2)\n",
    "\n",
    "        x = self.encoder_origin_1(x)\n",
    "        cnn = self.encoder_cnn_1(cnn)\n",
    "        lstm_output = self.encoder_lstm_1(lstm_output)\n",
    "\n",
    "        x = self.encoder_origin_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        cnn = self.encoder_cnn_2(cnn)\n",
    "        cnn = self.relu(cnn)\n",
    "        cnn = self.dropout(cnn)\n",
    "        lstm_output = self.encoder_lstm_2(lstm_output)\n",
    "        lstm_output = self.relu(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        x = self.feedforward_origin_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        cnn = self.feedforward_cnn_1(cnn)\n",
    "        cnn = self.relu(cnn)\n",
    "        cnn = self.dropout(cnn)\n",
    "        lstm_output = self.feedforward_lstm_1(lstm_output)\n",
    "        lstm_output = self.relu(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        x = self.decoder_origin_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        cnn = self.decoder_cnn_1(cnn)\n",
    "        cnn = self.relu(cnn)\n",
    "        cnn = self.dropout(cnn)\n",
    "        lstm_output = self.decoder_lstm_1(lstm_output)\n",
    "        lstm_output = self.relu(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        x = self.decoder_origin_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        cnn = self.decoder_cnn_2(cnn)\n",
    "        cnn = self.relu(cnn)\n",
    "        cnn = self.dropout(cnn)\n",
    "        lstm_output = self.decoder_lstm_2(lstm_output)\n",
    "        lstm_output = self.relu(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        x = self.decoder_origin_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        cnn = self.decoder_cnn_3(cnn)\n",
    "        cnn = self.relu(cnn)\n",
    "        cnn = self.dropout(cnn)\n",
    "        lstm_output = self.decoder_lstm_3(lstm_output)\n",
    "        lstm_output = self.relu(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        for_predict = torch.cat((x, cnn, lstm_output), dim=2)\n",
    "        x = self.predict(for_predict)\n",
    "\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(data):\n",
    "    tmp_data = []\n",
    "    tmp_target = []\n",
    "    tmp_id = []\n",
    "    for i in range(len(data)):\n",
    "        id_converter = []\n",
    "        for itr2 in range(len(data[i][0])):\n",
    "            for itr3 in range(len(data[i][0][itr2])):\n",
    "                # if data[i][0][itr2][itr3] >= 14:\n",
    "                #     data[i][0][itr2][itr3] = 1 \n",
    "                # else: \n",
    "                #     data[i][0][itr2][itr3] = 0\n",
    "                data[i][0][itr2][itr3] /= 16\n",
    "                if data[i][0][itr2][itr3]< 0.05:\n",
    "                    data[i][0][itr2][itr3] = 0.05\n",
    "            # if data[i][1][itr2][0]  >= 14: \n",
    "            #     data[i][1][itr2][0] = 0.95\n",
    "            # else: \n",
    "            #     data[i][1][itr2][0] = 0.05\n",
    "            data[i][1][itr2][0] /= 16\n",
    "            if data[i][1][itr2][0] < 0.05:\n",
    "                data[i][1][itr2][0] = 0.05\n",
    "        id_converter.append([data[i][2][0]] * 16)\n",
    "        tmp_data.append(data[i][0])\n",
    "        tmp_target.append(data[i][1])\n",
    "        tmp_id.append([copy.deepcopy(id_converter)])\n",
    "    return [torch.Tensor(tmp_data), torch.Tensor(tmp_target), torch.LongTensor(tmp_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./dataset_next_month.pickle', 'rb')\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "f = open('./dataset_next_month_target.pickle', 'rb')\n",
    "data_target = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for itr1 in data_target.keys():\n",
    "    data_list.append((data[str(itr1)], data_target[str(itr1)], [int(itr1) - 10000000]))\n",
    "dataset = MyDataset(data_list)\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset,[498000, 40])\n",
    "trainloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = NUM_WORKERS, collate_fn = collate_function)\n",
    "testloader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = NUM_WORKERS, collate_fn = collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[50394, 50394, 50394, 50394, 50394, 50394, 50394, 50394, 50394, 50394,\n",
      "          50394, 50394, 50394, 50394, 50394, 50394]]])\n"
     ]
    }
   ],
   "source": [
    "# print(len(dataloader))\n",
    "for data in iter(trainloader):\n",
    "    # print(inputs)\n",
    "    # print(labels)\n",
    "    # print(mask)\n",
    "    print(len(data[2][0]))\n",
    "    print(data[2][0])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.8125],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         ...,\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]],\n",
      "\n",
      "        [[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         ...,\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]],\n",
      "\n",
      "        [[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.8125, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.9375, 0.9375, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [0.0500, 1.0000, 0.8750,  ..., 0.8125, 0.9375, 0.8125],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         ...,\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 1.0000],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 1.0000, 0.0500]],\n",
      "\n",
      "        [[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 1.0000],\n",
      "         [0.9375, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         ...,\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.9375]],\n",
      "\n",
      "        [[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         ...,\n",
      "         [0.9375, 0.9375, 0.0500,  ..., 1.0000, 0.7500, 1.0000],\n",
      "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
      "         [0.0500, 1.0000, 1.0000,  ..., 0.0500, 0.8125, 0.0500]]]), tensor([[[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.8750],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.8125],\n",
      "         [1.0000],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.8750],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [1.0000],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.8750],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.8750],\n",
      "         [0.0500],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.8125],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.0500],\n",
      "         [0.8750],\n",
      "         [1.0000],\n",
      "         [0.9375],\n",
      "         [0.0500],\n",
      "         [0.0500]]]), tensor([[[[462152, 462152, 462152, 462152, 462152, 462152, 462152, 462152,\n",
      "           462152, 462152, 462152, 462152, 462152, 462152, 462152, 462152]]],\n",
      "\n",
      "\n",
      "        [[[224587, 224587, 224587, 224587, 224587, 224587, 224587, 224587,\n",
      "           224587, 224587, 224587, 224587, 224587, 224587, 224587, 224587]]],\n",
      "\n",
      "\n",
      "        [[[151083, 151083, 151083, 151083, 151083, 151083, 151083, 151083,\n",
      "           151083, 151083, 151083, 151083, 151083, 151083, 151083, 151083]]],\n",
      "\n",
      "\n",
      "        [[[223804, 223804, 223804, 223804, 223804, 223804, 223804, 223804,\n",
      "           223804, 223804, 223804, 223804, 223804, 223804, 223804, 223804]]],\n",
      "\n",
      "\n",
      "        [[[127691, 127691, 127691, 127691, 127691, 127691, 127691, 127691,\n",
      "           127691, 127691, 127691, 127691, 127691, 127691, 127691, 127691]]],\n",
      "\n",
      "\n",
      "        [[[444585, 444585, 444585, 444585, 444585, 444585, 444585, 444585,\n",
      "           444585, 444585, 444585, 444585, 444585, 444585, 444585, 444585]]],\n",
      "\n",
      "\n",
      "        [[[  2423,   2423,   2423,   2423,   2423,   2423,   2423,   2423,\n",
      "             2423,   2423,   2423,   2423,   2423,   2423,   2423,   2423]]],\n",
      "\n",
      "\n",
      "        [[[384809, 384809, 384809, 384809, 384809, 384809, 384809, 384809,\n",
      "           384809, 384809, 384809, 384809, 384809, 384809, 384809, 384809]]],\n",
      "\n",
      "\n",
      "        [[[ 34057,  34057,  34057,  34057,  34057,  34057,  34057,  34057,\n",
      "            34057,  34057,  34057,  34057,  34057,  34057,  34057,  34057]]],\n",
      "\n",
      "\n",
      "        [[[ 86410,  86410,  86410,  86410,  86410,  86410,  86410,  86410,\n",
      "            86410,  86410,  86410,  86410,  86410,  86410,  86410,  86410]]],\n",
      "\n",
      "\n",
      "        [[[153973, 153973, 153973, 153973, 153973, 153973, 153973, 153973,\n",
      "           153973, 153973, 153973, 153973, 153973, 153973, 153973, 153973]]],\n",
      "\n",
      "\n",
      "        [[[154712, 154712, 154712, 154712, 154712, 154712, 154712, 154712,\n",
      "           154712, 154712, 154712, 154712, 154712, 154712, 154712, 154712]]],\n",
      "\n",
      "\n",
      "        [[[ 73687,  73687,  73687,  73687,  73687,  73687,  73687,  73687,\n",
      "            73687,  73687,  73687,  73687,  73687,  73687,  73687,  73687]]],\n",
      "\n",
      "\n",
      "        [[[203008, 203008, 203008, 203008, 203008, 203008, 203008, 203008,\n",
      "           203008, 203008, 203008, 203008, 203008, 203008, 203008, 203008]]],\n",
      "\n",
      "\n",
      "        [[[363797, 363797, 363797, 363797, 363797, 363797, 363797, 363797,\n",
      "           363797, 363797, 363797, 363797, 363797, 363797, 363797, 363797]]],\n",
      "\n",
      "\n",
      "        [[[273355, 273355, 273355, 273355, 273355, 273355, 273355, 273355,\n",
      "           273355, 273355, 273355, 273355, 273355, 273355, 273355, 273355]]]])]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for test in trainloader:\n",
    "    print(test)\n",
    "    print(len(test[1][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=False)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# print(target)\n",
    "# print(input)\n",
    "# loss_fn(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'./exp_{LR}_final_{BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch :0 loss :7.595 val loss :0.0:   8%|▊         | 2337/31125 [02:23<28:25, 16.88it/s]"
     ]
    }
   ],
   "source": [
    "train_steps = 1\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "is_inception = False\n",
    "\n",
    "val_loss = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    cur_val_loss = val_loss\n",
    "    val_loss = 0.0\n",
    "\n",
    "    train_data = tqdm(iter(trainloader))\n",
    "    dataloaders = {'train' : train_data, 'val' : testloader}\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels, ids in iter(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ids = ids.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # Get model outputs and calculate loss\n",
    "                # Special case for inception because in training it has an auxiliary output. In train\n",
    "                #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                #   but in testing we only consider the final output.\n",
    "                if is_inception and phase == 'train':\n",
    "                    # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                    outputs, aux_outputs = model(inputs)\n",
    "                    loss1 = criterion(outputs, labels)\n",
    "                    loss2 = criterion(aux_outputs, labels)\n",
    "                    loss = loss1 + 0.4*loss2\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    # print(len(outputs))\n",
    "                    # print(len(outputs[0]))\n",
    "\n",
    "                    loss = torch.sum(torch.pow(torch.abs(torch.subtract(outputs, labels)),3), dim = 0)\n",
    "                    loss = torch.sum(loss, dim = 0)\n",
    "                    \n",
    "                # print(preds)\n",
    "                # print(labels.data)\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_steps += 1\n",
    "                    if(train_steps % 100) == 0:\n",
    "                        train_data.set_description(f'Epoch :{epoch}' + f' loss :{round(loss.item(), 3)}' + f' val loss :{cur_val_loss}')\n",
    "                        writer.add_scalar('training_loss', loss.item(), train_steps)        \n",
    "\n",
    "                    if(train_steps % 10000 ) == 0:\n",
    "                        torch.save(model.state_dict(), f'./exp_{LR}_final_{BATCH_SIZE}/' + str(train_steps) + '.model')\n",
    "                        # torch.save(optimizer.state_dict(), './exp_next_month_with_id_1e-5/optimizer_' + str(train_steps) + '.model')\n",
    "                    #print('propagation')\n",
    "                if phase == 'val':\n",
    "                    val_loss += round(loss.item(), 1)\n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Kernel is dead",
     "output_type": "error",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006305)",
      "at g.sendShellMessage (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006074)",
      "at g.requestExecute (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1008616)",
      "at d.requestExecute (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:37:328037)",
      "at S.requestExecute (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:32:19306)",
      "at w.executeCodeCell (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300924)",
      "at w.execute (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/home/incarnation/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "# ./exp_next_month_id_{LR}_multi_cnn/exp_next_month_id_{LR}_multi_cnn    infer 90000 120000\n",
    "# ./ exp_next_month_{LR}_multi_cnn"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d2fb2da1ead284111eca66b5f71903e4ac9fc311b7a7d2c42b50e9190f68909"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
